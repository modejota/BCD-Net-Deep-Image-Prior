{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "using device: cpu\n",
      "batch_size               : 2\n",
      "patch_size               : 128\n",
      "epochs                   : 5\n",
      "pretraining_epochs       : 1\n",
      "print_freq               : 1\n",
      "save_model_freq          : 20\n",
      "val_props                : 0.1\n",
      "lr_C                     : 0.0001\n",
      "lr_M                     : 0.0001\n",
      "gamma                    : 0.1\n",
      "clip_grad_C              : 10000.0\n",
      "clip_grad_M              : 100000.0\n",
      "train_data_path          : /data/BasesDeDatos/Camelyon/Camelyon17/training/Toy/\n",
      "pre_kernel_path          : \n",
      "log_dir                  : ./log\n",
      "model_dir                : ./model\n",
      "resume                   : \n",
      "num_workers              : 8\n",
      "sigmaRui_h_sq            : 0.001\n",
      "sigmaRui_e_sq            : 0.001\n",
      "theta                    : 0.5\n",
      "pre_kl                   : 100.0\n",
      "pre_mse                  : 0.01\n",
      "code_len                 : 30\n",
      "CNet                     : unet_6\n",
      "MNet                     : resnet_18_in\n",
      "max_size                 : 3\n",
      "dirichlet_para_stretch   : 20000\n",
      "prekernels               : \n",
      "nrow                     : 8\n",
      "epoch_start_test         : 20\n",
      "skip_grad                : 1000000.0\n",
      "warm_up_epoch            : 0\n",
      "kl_dir_weight            : 1.0\n",
      "run_mode                 : center_0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics import PeakSignalNoiseRatio\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "# import scipy.io\n",
    "# from utils.utils_metric import batch_PSNR, batch_SSIM\n",
    "\n",
    "import options \n",
    "\n",
    "from datasets.main_dataset import get_dataloaders\n",
    "from loss import loss_fn, loss_BCD\n",
    "from networks.cnet import get_cnet\n",
    "from networks.mnet import get_mnet\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "USE_GPU = True\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda:1')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print('using device:', DEVICE)\n",
    "#args = set_opts()\n",
    "args = options.set_opts_jp()\n",
    "for arg in vars(args):\n",
    "    print('{:<25s}: {:s}'.format(arg, str(getattr(args, arg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVBCDModel():\n",
    "    def __init__(self, args, device=\"cpu\"):\n",
    "        self.args = args\n",
    "        self.cnet = get_cnet(args.CNet)\n",
    "        self.mnet = get_mnet(args.MNet, kernel_size=3)\n",
    "        self.loss_fn = loss_BCD\n",
    "        self.device = device\n",
    "\n",
    "        self.sigmaRui_sq = torch.tensor([args.sigmaRui_h_sq, args.sigmaRui_e_sq])\n",
    "        self.theta = 0.5\n",
    "        self.pre_mse = args.pre_mse\n",
    "        self.pre_kl = args.pre_kl\n",
    "\n",
    "        self.optim_initiated = False\n",
    "        self.optimizers = None\n",
    "        self.lr_schedulers = None\n",
    "        \n",
    "    def forward(self, y):\n",
    "        out_MNet_mean, out_Mnet_var = self.mnet(y) # shape: (batch_size, 3, 2), (batch_size, 1, 2)\n",
    "        out_CNet = self.cnet(y) # shape: (batch_size, 2, H, W)\n",
    "        return out_MNet_mean, out_Mnet_var, out_CNet\n",
    "\n",
    "    def train(self):\n",
    "        self.cnet.train()\n",
    "        self.mnet.train()\n",
    "    \n",
    "    def eval(self):\n",
    "        self.cnet.eval()\n",
    "        self.mnet.eval()\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.cnet.to(device)\n",
    "        self.mnet.to(device)\n",
    "\n",
    "    def init_optimizers(self):\n",
    "        #pre_optimizer_CNet = optim.Adam(self.cnet.parameters(), lr=5e-4)\n",
    "        #pre_optimizer_MNet = optim.Adam(self.mnet.parameters(), lr=5e-4)\n",
    "        Cnet_opt = torch.optim.Adam(self.cnet.parameters(), lr=5e-4)\n",
    "        Mnet_opt = torch.optim.Adam(self.mnet.parameters(), lr=5e-4)\n",
    "        Cnet_sch = torch.optim.lr_scheduler.StepLR(Cnet_opt, step_size=20, gamma=0.1)\n",
    "        Mnet_sch = torch.optim.lr_scheduler.StepLR(Mnet_opt, step_size=20, gamma=0.1)\n",
    "\n",
    "        self.optimizers = (Cnet_opt, Mnet_opt)\n",
    "        self.lr_schedulers = (Cnet_sch, Mnet_sch)\n",
    "        self.optim_initiated = True\n",
    "\n",
    "    def training_step(self, batch, batch_idx, pretraining=False):\n",
    "\n",
    "        Cnet_opt, Mnet_opt = self.optimizers\n",
    "\n",
    "        y, mR = batch\n",
    "        y = y.to(self.device)\n",
    "        mR = mR.to(self.device)\n",
    "\n",
    "        Cnet_opt.zero_grad()\n",
    "        Mnet_opt.zero_grad()\n",
    "\n",
    "        out_Mnet_mean, out_Mnet_var = self.mnet(y) # shape: (batch_size, 3, 2), (batch_size, 1, 2)\n",
    "        out_Cnet = self.cnet(y) # shape: (batch_size, 2, H, W)\n",
    "\n",
    "        #loss, loss_mse, loss_kl, loss_kl_h, loss_kl_e = self.loss_fn(  out_CNet, out_MNet_mean, out_Mnet_var, y, mR,\n",
    "        #                                    self.args.sigmaRui_h_sq, self.args.sigmaRui_e_sq, \n",
    "        #                                    pretraining=True, pre_mse = self.args.pre_mse, pre_kl = self.args.pre_kl\n",
    "        #                                    )\n",
    "        \n",
    "        loss, loss_kl, loss_mse = loss_BCD(out_Cnet, out_Mnet_mean, out_Mnet_var, y, self.sigmaRui_sq, mR, self.theta, pretraining=pretraining, pre_mse = self.pre_mse, pre_kl = self.pre_kl)\n",
    "\n",
    "        loss.backward()\n",
    "        Cnet_opt.step()\n",
    "        Mnet_opt.step()\n",
    "\n",
    "        CNet_sch, MNet_sch = self.lr_schedulers\n",
    "        CNet_sch.step()\n",
    "        MNet_sch.step()\n",
    "\n",
    "        return {'train_loss' : loss.item(), 'train_loss_mse' : loss_mse.item(), 'train_loss_kl' : loss_kl.item()}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._shared_eval_step(batch, batch_idx, 'val')\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._shared_eval_step(batch, batch_idx, 'test')\n",
    "    \n",
    "    def _shared_eval_step(self, batch, batch_idx, prefix):\n",
    "\n",
    "        y, mR = batch\n",
    "        y = y.to(self.device)\n",
    "        mR = mR.to(self.device)\n",
    "\n",
    "        out_Mnet_mean, out_Mnet_var = self.mnet(y) # shape: (batch_size, 3, 2), (batch_size, 1, 2)\n",
    "        out_Cnet = self.cnet(y) # shape: (batch_size, 2, H, W)\n",
    "\n",
    "        #loss, loss_mse, loss_kl, loss_kl_h, loss_kl_e = self.loss_fn(  out_CNet, out_MNet_mean, out_Mnet_var, y, mR,\n",
    "        #                                    self.args.sigmaRui_h_sq, self.args.sigmaRui_e_sq, \n",
    "        #                                    pretraining=True, pre_mse = self.args.pre_mse, pre_kl = self.args.pre_kl\n",
    "        #                                    )\n",
    "        \n",
    "        loss, loss_kl, loss_mse = loss_BCD(out_Cnet, out_Mnet_mean, out_Mnet_var, y, self.sigmaRui_sq, mR, self.theta)\n",
    "\n",
    "        #psnr = PeakSignalNoiseRatio()\n",
    "        return {f'{prefix}_loss' : loss.item(), f'{prefix}_loss_mse' : loss_mse.item(), f'{prefix}_loss_kl' : loss_kl.item()}\n",
    "    \n",
    "    def fit(self, max_epochs, train_dataloader, val_dataloader=None, pretraining=False):\n",
    "        if val_dataloader is None:\n",
    "            val_dataloader = train_dataloader\n",
    "        \n",
    "        if not self.optim_initiated:\n",
    "            self.init_optimizers()\n",
    "        \n",
    "        self.sigmaRui_sq.to(self.device)\n",
    "        self.to(self.device)\n",
    "        for epoch in range(1, max_epochs + 1):\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            \n",
    "            # Trainining loop:\n",
    "            self.train()\n",
    "            pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "            pbar.set_description(f\"Epoch {epoch} - Training\")\n",
    "            for batch_idx, batch in pbar:\n",
    "                m_dic = self.training_step(batch, batch_idx, pretraining=pretraining)\n",
    "                pbar.set_postfix(m_dic)\n",
    "\n",
    "            # Eval loop\n",
    "            self.eval()\n",
    "            pbar = tqdm(enumerate(val_dataloader), total=len(val_dataloader))\n",
    "            pbar.set_description(f\"Epoch {epoch} - Validation\")\n",
    "            for batch_idx, batch in pbar:\n",
    "                m_dic = self.validation_step(batch, batch_idx)\n",
    "                pbar.set_postfix(m_dic)\n",
    "\n",
    "    def evaluate(self, test_dataloader):\n",
    "        self.eval()\n",
    "        pbar = tqdm(enumerate(test_dataloader), total=len(test_dataloader))\n",
    "        pbar.set_description(f\"Testing\")\n",
    "        for batch_idx, batch in pbar:\n",
    "            m_dic = self.test_step(batch, batch_idx)\n",
    "            pbar.set_postfix(m_dic)\n",
    "        return m_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available patches: 1247945\n",
      "Available patches: 1813651\n",
      "70000 30000\n"
     ]
    }
   ],
   "source": [
    "#args.train_data_path = '/data/BasesDeDatos/Camelyon/Camelyon17/training/Toy/'\n",
    "args.train_data_path = '/data/BasesDeDatos/Camelyon/Camelyon17/training/patches_224/'\n",
    "\n",
    "dataloaders = get_dataloaders(args, val_prop=0.3)\n",
    "train_dataloader = dataloaders['train']\n",
    "val_dataloader = dataloaders['val']\n",
    "print(len(train_dataloader), len(val_dataloader))\n",
    "test_dataloader = dataloaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 42/70000 [00:30<14:04:39,  1.38it/s, train_loss=184, train_loss_mse=66.8, train_loss_kl=302]          "
     ]
    }
   ],
   "source": [
    "model = DVBCDModel(args, DEVICE)\n",
    "model.fit(5, train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DVBCD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6ad41a6645221cf1bf85d33afd32a0947fad2555ebbd1ea9580495d050a48a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
