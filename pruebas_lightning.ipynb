{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n",
      "using device: cpu\n",
      "batch_size               : 2\n",
      "patch_size               : 128\n",
      "epochs                   : 5\n",
      "pretraining_epochs       : 1\n",
      "print_freq               : 1\n",
      "save_model_freq          : 20\n",
      "val_props                : 0.1\n",
      "lr_C                     : 0.0001\n",
      "lr_M                     : 0.0001\n",
      "gamma                    : 0.1\n",
      "clip_grad_C              : 10000.0\n",
      "clip_grad_M              : 100000.0\n",
      "train_data_path          : /data/BasesDeDatos/Camelyon/Camelyon17/training/Toy/\n",
      "pre_kernel_path          : \n",
      "log_dir                  : ./log\n",
      "model_dir                : ./model\n",
      "resume                   : \n",
      "num_workers              : 8\n",
      "sigmaRui_h_sq            : 0.001\n",
      "sigmaRui_e_sq            : 0.001\n",
      "theta                    : 0.5\n",
      "pre_kl                   : 100.0\n",
      "pre_mse                  : 0.01\n",
      "code_len                 : 30\n",
      "CNet                     : unet_6\n",
      "MNet                     : resnet_18_in\n",
      "max_size                 : 3\n",
      "dirichlet_para_stretch   : 20000\n",
      "prekernels               : \n",
      "nrow                     : 8\n",
      "epoch_start_test         : 20\n",
      "skip_grad                : 1000000.0\n",
      "warm_up_epoch            : 0\n",
      "kl_dir_weight            : 1.0\n",
      "run_mode                 : center_0\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics import PeakSignalNoiseRatio\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "# import scipy.io\n",
    "# from utils.utils_metric import batch_PSNR, batch_SSIM\n",
    "\n",
    "import options \n",
    "\n",
    "from datasets.main_dataset import get_dataloaders\n",
    "from loss import loss_fn\n",
    "from networks.dnet import get_dnet\n",
    "from networks.knet import get_knet\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "USE_GPU = False\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda:1')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('using device:', device)\n",
    "#args = set_opts()\n",
    "args = options.set_opts_jp()\n",
    "for arg in vars(args):\n",
    "    print('{:<25s}: {:s}'.format(arg, str(getattr(args, arg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVBCDModel(pl.LightningModule):\n",
    "    def __init__(self, args):\n",
    "        super(DVBCDModel, self).__init__()\n",
    "        self.args = args\n",
    "        self.cnet = get_dnet(args.CNet)\n",
    "        self.mnet = get_knet(args.MNet, kernel_size=3)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.automatic_optimization = False\n",
    "        #self.example_input_array = torch.rand(1, 1, 64, 64)\n",
    "        #self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, y):\n",
    "        out_MNet_mean, out_Mnet_var = self.mnet(y) # shape: (batch_size, 3, 2), (batch_size, 1, 2)\n",
    "        out_CNet = self.cnet(y) # shape: (batch_size, 2, H, W)\n",
    "        return out_MNet_mean, out_Mnet_var, out_CNet\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        #pre_optimizer_CNet = optim.Adam(self.cnet.parameters(), lr=5e-4)\n",
    "        #pre_optimizer_MNet = optim.Adam(self.mnet.parameters(), lr=5e-4)\n",
    "        CNet_opt = torch.optim.Adam(self.cnet.parameters(), lr=5e-4)\n",
    "        MNet_opt = torch.optim.Adam(self.mnet.parameters(), lr=5e-4)\n",
    "        CNet_sch = torch.optim.lr_scheduler.StepLR(CNet_opt, step_size=20, gamma=0.1)\n",
    "        MNet_sch = torch.optim.lr_scheduler.StepLR(MNet_opt, step_size=20, gamma=0.1)\n",
    "        return [CNet_opt, MNet_opt], [CNet_sch, MNet_sch]\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        CNet_opt, MNet_opt = self.optimizers()\n",
    "\n",
    "        y, mR = batch\n",
    "        #y = y.to(device)\n",
    "        #mR = mR.to(device)\n",
    "\n",
    "        CNet_opt.zero_grad()\n",
    "        MNet_opt.zero_grad()\n",
    "\n",
    "        out_MNet_mean, out_Mnet_var = self.mnet(y) # shape: (batch_size, 3, 2), (batch_size, 1, 2)\n",
    "        out_CNet = self.cnet(y) # shape: (batch_size, 2, H, W)\n",
    "\n",
    "        loss, loss_mse, loss_kl, loss_kl_h, loss_kl_e = self.loss_fn(  out_CNet, out_MNet_mean, out_Mnet_var, y, mR,\n",
    "                                            self.args.sigmaRui_h_sq, self.args.sigmaRui_e_sq, \n",
    "                                            pretraining=True, pre_mse = self.args.pre_mse, pre_kl = self.args.pre_kl\n",
    "                                            )\n",
    "        \n",
    "        self.manual_backward(loss)\n",
    "        CNet_opt.step()\n",
    "        MNet_opt.step()\n",
    "\n",
    "        CNet_sch, MNet_sch = self.lr_schedulers()\n",
    "        CNet_sch.step()\n",
    "        MNet_sch.step()\n",
    "\n",
    "        self.log_dict({'loss' : loss, 'loss_mse' : loss_mse, 'loss_kl' : loss_kl}, logger=True, prog_bar=True)\n",
    "        return {'loss' : loss, 'loss_mse' : loss_mse, 'loss_kl' : loss_kl}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, 'val')\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._shared_eval(batch, batch_idx, 'test')\n",
    "    \n",
    "    def _shared_eval(self, batch, batch_idx, prefix):\n",
    "\n",
    "        y, mR = batch\n",
    "        #y = y.to(device)\n",
    "        #mR = mR.to(device)\n",
    "\n",
    "        out_MNet_mean, out_Mnet_var = self.mnet(y) # shape: (batch_size, 3, 2), (batch_size, 1, 2)\n",
    "        out_CNet = self.cnet(y) # shape: (batch_size, 2, H, W)\n",
    "\n",
    "        loss, loss_mse, loss_kl, loss_kl_h, loss_kl_e = self.loss_fn(\n",
    "                                                        out_CNet, out_MNet_mean, out_Mnet_var, y, mR,\n",
    "                                                        self.args.sigmaRui_h_sq, self.args.sigmaRui_e_sq\n",
    "                                                        )\n",
    "\n",
    "        #psnr = PeakSignalNoiseRatio()\n",
    "        if prefix == 'val':\n",
    "            to_logger = True\n",
    "            to_progbar = True\n",
    "        else:\n",
    "            to_logger = False\n",
    "            to_progbar = False\n",
    "        self.log_dict({f'{prefix}_loss' : loss, f'{prefix}_loss_mse' : loss_mse, f'{prefix}_loss_kl' : loss_kl}, logger=to_logger, prog_bar=to_progbar)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available patches: 6\n",
      "Available patches: 4\n",
      "3 1\n"
     ]
    }
   ],
   "source": [
    "dataloaders = get_dataloaders(args, val_prop=0.3)\n",
    "train_dataloader = dataloaders['train']\n",
    "val_dataloader = dataloaders['val']\n",
    "print(len(train_dataloader), len(val_dataloader))\n",
    "test_dataloader = dataloaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping, TQDMProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | cnet | UNet       | 5.0 M \n",
      "1 | mnet | ResNet18IN | 11.2 M\n",
      "------------------------------------\n",
      "16.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.2 M    Total params\n",
      "64.741    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05acfffc8167479d8448d2a89ea3a31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80700d9b4bda417a80c7cf3b5ed8b3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11439ec01b042969805fc24e7baacca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5), TQDMProgressBar(refresh_rate=1)]\n",
    "trainer = pl.Trainer(accelerator=\"cpu\", callbacks=callbacks, max_epochs=10, enable_progress_bar=True, log_every_n_steps=1)\n",
    "model = DVBCDModel(args)\n",
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DVBCD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6ad41a6645221cf1bf85d33afd32a0947fad2555ebbd1ea9580495d050a48a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
