{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from models import Cnet, BCDnet\n",
    "from datasets import WSSBDatasetTest\n",
    "from utils import od2rgb, rgb2od, random_ruifrok_matrix_variation, direct_deconvolution, peak_signal_noise_ratio, structural_similarity, askforPyTorchWeightsviaGUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_GROUND_TRUTH_IMAGES = False\n",
    "SAVE_MODEL_GENERATED_IMAGES = False\n",
    "SAVE_IMAGES_FREQUENCY = 200 # Interval between saving images (in iterations) generated by the model\n",
    "SAVE_WEIGHTS = False\n",
    "RUN_FROM_WEIGHTS = False\n",
    "\n",
    "APPROACH_USED = 'bcdnet_e1' # bcdnet_e1, bcdnet_e2, cnet_e2\n",
    "BATCH_SIZE = 1  # Should always be 1\n",
    "SIGMA_RUI_SQ = 0.05 # Prior hematoxylin/eosin variance of M\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "ORGAN = \"Colon\" # Lung, Breast or Colon\n",
    "IMAGE_TO_LOAD = 3\n",
    "RUNNING_ON_DELFOS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['toolbar'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsubaie_dataset_path = '/home/modej/Alsubaie_500x500' if RUNNING_ON_DELFOS else '../Alsubaie_500x500'\n",
    "\n",
    "dataset = WSSBDatasetTest(alsubaie_dataset_path, organ_list=[ORGAN], load_at_init=False)\n",
    "original_image, M_gt, _ = dataset[IMAGE_TO_LOAD]\n",
    "print('Image shape:', original_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 4000\n",
    "\n",
    "metrics_dict = { \n",
    "    'epoch' : 0, 'loss': 0.0, \n",
    "    'mse_rec' : 0.0, 'psnr_rec': 0.0, 'ssim_rec': 0.0,\n",
    "    'mse_gt_h': 0.0, 'mse_gt_e': 0.0, 'mse_gt': 0.0,\n",
    "    'psnr_gt_h': 0.0, 'psnr_gt_e': 0.0, 'psnr_gt': 0.0,\n",
    "    'ssim_gt_h': 0.0, 'ssim_gt_e': 0.0, 'ssim_gt': 0.0, 'time': 0.0    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_route = f'../../results/{APPROACH_USED}/per_image_training/{ORGAN}_{IMAGE_TO_LOAD}'\n",
    "if not os.path.exists(folder_route):\n",
    "    os.makedirs(folder_route)\n",
    "\n",
    "if not os.path.exists(f'{folder_route}/images'):\n",
    "    os.makedirs(f'{folder_route}/images')\n",
    "\n",
    "metrics_filepath = f'{folder_route}/metrics.csv'\n",
    "if os.path.exists(metrics_filepath):\n",
    "    os.remove(metrics_filepath)\n",
    "\n",
    "with(open(metrics_filepath, 'w')) as file:\n",
    "    header = ','.join(metrics_dict.keys()) + '\\n'\n",
    "    file.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all images derivated from the ground truth.\n",
    "img_np = original_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "img_od = rgb2od(original_image)\n",
    "\n",
    "C_gt = direct_deconvolution(img_od, M_gt).unsqueeze(0) # (1, 2, H, W)\n",
    "M_gt = M_gt.unsqueeze(0) # (1, 3, 2)\n",
    "\n",
    "C_H_gt_np = C_gt[:, 0, :, :].squeeze().numpy() # (H, W)\n",
    "C_E_gt_np = C_gt[:, 1, :, :].squeeze().numpy() # (H, W)\n",
    "\n",
    "gt_od = torch.einsum('bcs,bshw->bschw', M_gt, C_gt)\n",
    "H_gt_od = gt_od[:,0,:,:]\n",
    "H_gt = torch.clamp(od2rgb(H_gt_od), 0.0, 255.0) # (batch_size, 3, H, W)\n",
    "E_gt_od = gt_od[:,1,:,:]\n",
    "E_gt = torch.clamp(od2rgb(E_gt_od), 0.0, 255.0) # (batch_size, 3, H, W)\n",
    "\n",
    "H_gt_np = H_gt.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "E_gt_np = E_gt.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "\n",
    "if SAVE_GROUND_TRUTH_IMAGES:\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "    ax[0].imshow(img_np)\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(C_H_gt_np, cmap='gray')\n",
    "    ax[1].set_title('Original Hematoxylin\\nConcentration')\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    ax[2].imshow(C_E_gt_np, cmap='gray')\n",
    "    ax[2].set_title('Original Eosin\\nConcentration')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    ax[3].imshow(H_gt_np)\n",
    "    ax[3].set_title('Original Hematoxylin')\n",
    "    ax[3].axis('off')\n",
    "\n",
    "    ax[4].imshow(E_gt_np)\n",
    "    ax[4].set_title('Original Eosin')\n",
    "    ax[4].axis('off')\n",
    "\n",
    "    plt.savefig(f'{folder_route}/images/ground_truth_image.png', transparent=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to GPU, we gonna need it later during traning for metrics' calculation.\n",
    "H_gt = H_gt.to(device)\n",
    "H_gt_od = H_gt_od.to(device)\n",
    "E_gt = E_gt.to(device)\n",
    "E_gt_od = E_gt_od.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_noise = torch.rand(original_image.shape).unsqueeze(0).to(device)  # Unsqueezed to add the batch dimension, it needs to be ([1, 3, x, y])\n",
    "original_tensor = original_image.unsqueeze(0).to(device) \n",
    "_, _, H, W = original_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'bcdnet' in APPROACH_USED:\n",
    "    model = BCDnet(cnet_name='unet_64_6', mnet_name='mobilenetv3s_50').to(device)\n",
    "elif 'cnet' in APPROACH_USED:\n",
    "    model = Cnet().to(device)\n",
    "else:\n",
    "    raise Exception('Approach not found.')\n",
    "\n",
    "if RUN_FROM_WEIGHTS:\n",
    "    weightsfile = askforPyTorchWeightsviaGUI()  # The functions already manages exceptions\n",
    "    model.load_state_dict(torch.load(weightsfile))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_data = range(1, NUM_ITERATIONS+1)\n",
    "for iteration in tqdm(loop_data, desc=\"Processing image\", unit=\"iterations\"):\n",
    "\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if APPROACH_USED in ['bcdnet_e1', 'bcdnet_e2']:\n",
    "        # Using BCDnet we obtain both the concentration matrix and the colors matrix as well as the colors' variation\n",
    "        M_matrix, M_variation, C_matrix = model(input_noise)\n",
    "\n",
    "    elif APPROACH_USED == 'cnet_e2':\n",
    "        # Using Cnet we just obtain the concentration matrix\n",
    "        C_matrix = model(input_noise)\n",
    "    \n",
    "        # Generate the colors matrix as a sample of a gaussian distribution given the Ruifrok matrix\n",
    "        h_matrix, e_matrix = random_ruifrok_matrix_variation(SIGMA_RUI_SQ)\n",
    "        M_matrix = np.concatenate((h_matrix,e_matrix),axis=1)                   # ([1, 3, 2])\n",
    "        M_matrix = torch.from_numpy(M_matrix).float().unsqueeze(0).to(device)   # ([1, 2, x, y])\n",
    "\n",
    "    # Generate the 3 channels image and get it back to RGB\n",
    "    reconstructed_od = torch.einsum('bcs,bshw->bchw', M_matrix, C_matrix)   # ([1, 3, x, y])\n",
    "    reconstructed = torch.clamp(od2rgb(reconstructed_od), 0, 255.0)\n",
    "\n",
    "    if APPROACH_USED in ['bcdnet_e1', 'cnet_e2']:\n",
    "        loss = torch.nn.functional.mse_loss(reconstructed, original_tensor)\n",
    "    \n",
    "    elif APPROACH_USED == 'bcdnet_e2':\n",
    "        ruifrok_matrix = torch.tensor([\n",
    "                            [0.6442, 0.0928],\n",
    "                            [0.7166, 0.9541],\n",
    "                            [0.2668, 0.2831]\n",
    "                            ]).type(torch.float32)\n",
    "        ruifrok_matrix = ruifrok_matrix.repeat(BATCH_SIZE, 1, 1).to(device)  # (batch_size, 3, 2)\n",
    "        M_variation = M_variation.repeat(1, 3, 1)   # (batch_size, 3, 2) \n",
    "        # Calculate the Kullback-Leiber divergence via its closed form\n",
    "        loss_kl = (0.5 / SIGMA_RUI_SQ) * torch.nn.functional.mse_loss(M_matrix, ruifrok_matrix, reduction='none') + 1.5 * (M_variation / SIGMA_RUI_SQ - torch.log(M_variation / SIGMA_RUI_SQ) - 1) # (batch_size, 3, 2)\n",
    "        loss_kl = torch.sum(loss_kl) / BATCH_SIZE # (1)\n",
    "        loss_mse = torch.nn.functional.mse_loss(reconstructed, original_tensor)\n",
    "        loss = loss_mse + loss_kl\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate general metrics and reconstruction metrics\n",
    "    metrics_dict['time'] = ((time.time() - start_time) * 1000.0)  # Milliseconds\n",
    "    metrics_dict['epoch'] = iteration\n",
    "    metrics_dict['loss'] = loss.item()\n",
    "    metrics_dict['mse_rec'] = torch.sum(torch.pow(reconstructed_od - rgb2od(original_tensor), 2)).item() / (3.0*H*W)    \n",
    "    metrics_dict['psnr_rec'] = torch.sum(peak_signal_noise_ratio(reconstructed, original_tensor)).item()\n",
    "    metrics_dict['ssim_rec'] = torch.sum(structural_similarity(reconstructed, original_tensor)).item()\n",
    "\n",
    "    # Generate the images from the model\n",
    "    C_mean = C_matrix.detach().cpu()\n",
    "    img_rec_np = reconstructed.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "    \n",
    "    C_H_rec_np = C_mean[:, 0, :, :].squeeze().numpy() \n",
    "    C_E_rec_np = C_mean[:, 1, :, :].squeeze().numpy()\n",
    "\n",
    "    rec_od = torch.einsum('bcs,bshw->bschw', M_matrix, C_matrix)\n",
    "    H_rec_od = rec_od[:,0,:,:] \n",
    "    H_rec = torch.clamp(od2rgb(H_rec_od), 0.0, 255.0) \n",
    "    E_rec_od = rec_od[:,1,:,:]\n",
    "    E_rec = torch.clamp(od2rgb(E_rec_od), 0.0, 255.0)\n",
    "\n",
    "    H_rec_np = H_rec.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "    E_rec_np = E_rec.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "\n",
    "    # Calculate the metrics comparing with the ground truth\n",
    "    metrics_dict['mse_gt_h'] = torch.sum(torch.pow(H_gt_od - H_rec_od, 2)).item() / (3.0*H*W)\n",
    "    metrics_dict['mse_gt_e'] = torch.sum(torch.pow(E_gt_od - E_rec_od, 2)).item() / (3.0*H*W)\n",
    "\n",
    "    metrics_dict['psnr_gt_h'] = torch.sum(peak_signal_noise_ratio(H_gt, H_rec)).item()\n",
    "    metrics_dict['psnr_gt_e'] = torch.sum(peak_signal_noise_ratio(E_gt, E_rec)).item()\n",
    "\n",
    "    metrics_dict['ssim_gt_h'] = torch.sum(structural_similarity(H_gt, H_rec)).item()\n",
    "    metrics_dict['ssim_gt_e'] = torch.sum(structural_similarity(E_gt, E_rec)).item() \n",
    "\n",
    "    metrics_dict['mse_gt'] = (metrics_dict['mse_gt_h'] + metrics_dict['mse_gt_e'])/2.0\n",
    "    metrics_dict['psnr_gt'] = (metrics_dict['psnr_gt_h'] + metrics_dict['psnr_gt_e'])/2.0\n",
    "    metrics_dict['ssim_gt'] = (metrics_dict['ssim_gt_h'] + metrics_dict['ssim_gt_e'])/2.0\n",
    "\n",
    "    # Save the metrics in a csv file\n",
    "    with open(metrics_filepath, mode='a') as file:\n",
    "        data_row = ','.join(str(val) for val in metrics_dict.values()) + '\\n'\n",
    "        file.write(data_row)\n",
    "\n",
    "    if SAVE_MODEL_GENERATED_IMAGES and (iteration % SAVE_IMAGES_FREQUENCY == 0 or iteration == NUM_ITERATIONS or iteration == 1):\n",
    "        # Plot the generated images via the model\n",
    "        fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
    "        ax[0].imshow(img_rec_np)\n",
    "        ax[0].set_title('Reconstructed Image')\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(C_H_rec_np, cmap='gray')\n",
    "        ax[1].set_title('Reconstructed Hematoxylin\\nConcentration')\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(C_E_rec_np, cmap='gray')\n",
    "        ax[2].set_title('Reconstructed Eosin\\nConcentration')\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        ax[3].imshow(H_rec_np)\n",
    "        ax[3].set_title('Reconstructed Hematoxylin')\n",
    "        ax[3].axis('off')\n",
    "\n",
    "        ax[4].imshow(E_rec_np)\n",
    "        ax[4].set_title('Reconstructed Eosin')\n",
    "        ax[4].axis('off')\n",
    "\n",
    "        plt.savefig(f'{folder_route}/images/iteration_{iteration}.png', transparent=True)\n",
    "        plt.close()\n",
    "\n",
    "# Save weights at the end in case we want to train further from this point.\n",
    "if SAVE_WEIGHTS:\n",
    "    save_weights_filepath = f'{folder_route}/iteration_{NUM_ITERATIONS}.pt'\n",
    "    if os.path.exists(save_weights_filepath):\n",
    "        new_number_iterations = int(save_weights_filepath.split('_')[-1].split('.')[0]) + NUM_ITERATIONS\n",
    "        save_weights_filepath = f'{folder_route}/iteration_{new_number_iterations}.pt'\n",
    "    torch.save(model.state_dict(), save_weights_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCDNET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
