{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import Cnet\n",
    "from datasets import WSSBDatasetTest\n",
    "from utils import od2rgb, rgb2od, random_ruifrok_matrix_variation, direct_deconvolution, peak_signal_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_IMAGES = True\n",
    "RUNNING_ON_DELFOS = True\n",
    "\n",
    "torch.manual_seed(0)\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['toolbar'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUNNING_ON_DELFOS:\n",
    "    alsubaie_dataset_path = '/data/datasets/Alsubaie/Data/'\n",
    "else:\n",
    "    alsubaie_dataset_path = '../Alsubaie/Data/'\n",
    "\n",
    "dataset = WSSBDatasetTest(alsubaie_dataset_path, organ_list=['Colon'], load_at_init=False)\n",
    "original_image, M_gt = dataset[0]\n",
    "print('Image shape:', original_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all images derivated from the ground truth.\n",
    "\n",
    "img_np = original_image.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "img_od = rgb2od(original_image)\n",
    "\n",
    "C_gt = direct_deconvolution(img_od, M_gt)\n",
    "M_gt = M_gt.unsqueeze(0) # (1, 3, 2)\n",
    "C_gt = C_gt.unsqueeze(0) # (1, 2, 224, 224)\n",
    "\n",
    "M_gt_rgb = torch.clamp(od2rgb(M_gt / np.log(256)), 0.0, 255.0) # (1, 3, 2)\n",
    "M_gt_rgb_np = M_gt_rgb.squeeze().detach().cpu().numpy().transpose(1, 0).astype('int') # (2, 3)\n",
    "\n",
    "C_H_gt_od = C_gt[:, 0, :, :].squeeze() # (224, 224)\n",
    "C_H_gt = torch.clamp(od2rgb(C_H_gt_od), 0.0, 255.0)\n",
    "C_H_gt_np = C_gt[:, 0, :, :].squeeze().numpy() # (224, 224)\n",
    "\n",
    "C_E_gt_od = C_gt[:, 1, :, :].squeeze() # (224, 224)\n",
    "C_E_gt = torch.clamp(od2rgb(C_E_gt_od), 0.0, 255.0)\n",
    "C_E_gt_np = C_gt[:, 1, :, :].squeeze().numpy() # (224, 224)\n",
    "\n",
    "H_gt_od = torch.einsum('bcs,bshw->bschw', M_gt, C_gt)[:,0,:,:] # (batch_size, H, W)\n",
    "H_gt = torch.clamp(od2rgb(H_gt_od), 0.0, 255.0) # (batch_size, 3, H, W)\n",
    "E_gt_od = torch.einsum('bcs,bshw->bschw', M_gt, C_gt)[:,1,:,:] # (batch_size, H, W)\n",
    "E_gt = torch.clamp(od2rgb(E_gt_od), 0.0, 255.0) # (batch_size, 3, H, W)\n",
    "\n",
    "H_gt_np = H_gt.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "E_gt_np = E_gt.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_od = img_od.to(device)\n",
    "H_gt = H_gt.to(device)\n",
    "H_gt_od = H_gt_od.to(device)\n",
    "E_gt = E_gt.to(device)\n",
    "E_gt_od = E_gt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ground truth images.\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "ax[0].imshow(img_np)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(C_H_gt_np, cmap='gray')\n",
    "ax[1].set_title('Original Hematoxylin\\nConcentration')\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(C_E_gt_np, cmap='gray')\n",
    "ax[2].set_title('Original Eosin\\nConcentration')\n",
    "ax[2].axis('off')\n",
    "\n",
    "ax[3].imshow(H_gt_np)\n",
    "ax[3].set_title('Original Hematoxylin')\n",
    "ax[3].axis('off')\n",
    "\n",
    "ax[4].imshow(E_gt_np)\n",
    "ax[4].set_title('Original Eosin')\n",
    "ax[4].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 5000\n",
    "# Acceptable results in approximately 1000 epochs. \\n\n",
    "# It improves from there, but it does not finish converging and it goes pendulum.\n",
    "# It is not profitable to use more than 4000-5000 iterations. Current minor loss in epoch=4800, see results' foler.\n",
    "\n",
    "metrics_dict = { \n",
    "    'loss': 0.0, 'mse_rec' : 0.0, 'psnr_rec': 0.0,\n",
    "    'mse_gt_h': 0.0, 'mse_gt_e': 0.0, 'mse_gt': 0.0,\n",
    "    'psnr_gt_h': 0.0, 'psnr_gt_e': 0.0, 'psnr_gt': 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cnet().to(device)\n",
    "input_noise = torch.rand(original_image.shape).unsqueeze(0).to(device)  # Unsqueezed to add the batch dimension, it needs to be ([1, 3, x, y])\n",
    "original_tensor = original_image.unsqueeze(0).to(device) \n",
    "_, _, H, W = original_tensor.shape               \n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_ITERATIONS+1):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    C_mean = model(input_noise)\n",
    "\n",
    "    # Generate the colors matrix as a sample of a gaussian distribution given the Ruifrok matrix\n",
    "    h_matrix, e_matrix = random_ruifrok_matrix_variation(0.05)\n",
    "    M_matrix = np.concatenate((h_matrix,e_matrix),axis=1)                   # ([1, 3, 2])\n",
    "    M_matrix = torch.from_numpy(M_matrix).float().unsqueeze(0).to(device)   # ([1, 2, x, y])\n",
    "\n",
    "    # Generate the 3 channels image and get it back to RGB\n",
    "    reconstructed = torch.einsum('bcs,bshw->bchw', M_matrix, C_mean)   # ([1, 3, x, y])\n",
    "    metrics_dict['mse_rec'] = torch.sum(torch.pow(reconstructed - img_od, 2)).item() / (3.0*H*W)\n",
    "    reconstructed = torch.clamp(od2rgb(reconstructed), 0, 255.0)              \n",
    "    metrics_dict['psnr_rec'] += torch.sum(peak_signal_noise_ratio(reconstructed, original_tensor)).item()\n",
    "\n",
    "    loss = torch.nn.functional.mse_loss(reconstructed, original_tensor)\n",
    "    metrics_dict['loss'] = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Inteded to be used in a script, and not in a Jupyter, since it does not update the graph but regenerates it in the cell output. For the moment I'm just saving it.\n",
    "    if epoch % 200 == 0:\n",
    "\n",
    "        # Generate the images from the model\n",
    "        C_mean = C_mean.detach().cpu()\n",
    "        img_rec_np = reconstructed.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "        \n",
    "        C_H_rec_od = C_mean[:, 0, :, :].squeeze() \n",
    "        C_H_rec = torch.clamp(od2rgb(C_H_rec_od), 0.0, 255.0)\n",
    "        C_H_rec_np = C_mean[:, 0, :, :].squeeze().numpy() \n",
    "        C_E_rec_od = C_mean[:, 1, :, :].squeeze()\n",
    "        C_E_rec = torch.clamp(od2rgb(C_E_rec_od), 0.0, 255.0)\n",
    "        C_E_rec_np = C_mean[:, 1, :, :].squeeze().numpy()\n",
    "\n",
    "        H_rec_od = torch.einsum('bcs,bshw->bschw', M_matrix, C_mean)[:,0,:,:] \n",
    "        H_rec = torch.clamp(od2rgb(H_rec_od), 0.0, 255.0) \n",
    "        E_rec_od = torch.einsum('bcs,bshw->bschw', M_matrix, C_mean)[:,1,:,:]\n",
    "        E_rec = torch.clamp(od2rgb(E_rec_od), 0.0, 255.0)\n",
    "\n",
    "        H_rec_np = H_rec.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "        E_rec_np = E_rec.squeeze().detach().cpu().numpy().transpose(1, 2, 0).astype('uint8')\n",
    "\n",
    "        \n",
    "        metrics_dict['mse_gt_h'] += torch.sum(torch.pow(H_gt_od - H_rec_od, 2)).item() / (3.0*H*W)\n",
    "        metrics_dict['mse_gt_e'] += torch.sum(torch.pow(E_gt_od - E_rec_od, 2)).item() / (3.0*H*W)\n",
    "\n",
    "        metrics_dict['psnr_gt_h'] += torch.sum(peak_signal_noise_ratio(H_gt, H_rec)).item()\n",
    "        metrics_dict['psnr_gt_e'] += torch.sum(peak_signal_noise_ratio(E_gt, E_rec)).item()\n",
    "\n",
    "        metrics_dict['mse_gt'] = (metrics_dict['mse_gt_h'] + metrics_dict['mse_gt_e'])/2.0\n",
    "        metrics_dict['psnr_gt'] = (metrics_dict['psnr_gt_h'] + metrics_dict['psnr_gt_e'])/2.0\n",
    "\n",
    "        with open('/home/modej/Deep_Var_BCD/results/dip_images/metricas.txt', 'a') as archivo:\n",
    "            archivo.write(f\"Epoch: {epoch}\\n\")\n",
    "            for key in metrics_dict:\n",
    "                archivo.write(f\"{key} -> {metrics_dict[key]}\\n\")\n",
    "            archivo.write(\"\\n\")\n",
    "\n",
    "        if SAVE_IMAGES:\n",
    "            # Plot the ground truth images\n",
    "            fig, ax = plt.subplots(2, 5, figsize=(20, 9))\n",
    "\n",
    "            ax[0,0].imshow(img_np)\n",
    "            ax[0,0].set_title('Original Image')\n",
    "            ax[0,0].axis('off')\n",
    "\n",
    "            ax[0,1].imshow(C_H_gt_np, cmap='gray')\n",
    "            ax[0,1].set_title('Original Hematoxylin\\nConcentration')\n",
    "            ax[0,1].axis('off')\n",
    "\n",
    "            ax[0,2].imshow(C_E_gt_np, cmap='gray')\n",
    "            ax[0,2].set_title('Original Eosin\\nConcentration')\n",
    "            ax[0,2].axis('off')\n",
    "\n",
    "            ax[0,3].imshow(H_gt_np)\n",
    "            ax[0,3].set_title('Original Hematoxylin')\n",
    "            ax[0,3].axis('off')\n",
    "\n",
    "            ax[0,4].imshow(E_gt_np)\n",
    "            ax[0,4].set_title('Original Eosin')\n",
    "            ax[0,4].axis('off')\n",
    "\n",
    "            # Plot the generated images via the model\n",
    "            ax[1,0].imshow(img_rec_np)\n",
    "            ax[1,0].set_title('Reconstructed Image')\n",
    "            ax[1,0].axis('off')\n",
    "\n",
    "            ax[1,1].imshow(C_H_rec_np, cmap='gray')\n",
    "            ax[1,1].set_title('Reconstructed Hematoxylin\\nConcentration')\n",
    "            ax[1,1].axis('off')\n",
    "\n",
    "            ax[1,2].imshow(C_E_rec_np, cmap='gray')\n",
    "            ax[1,2].set_title('Reconstructed Eosin\\nConcentration')\n",
    "            ax[1,2].axis('off')\n",
    "\n",
    "            ax[1,3].imshow(H_rec_np)\n",
    "            ax[1,3].set_title('Reconstructed Hematoxylin')\n",
    "            ax[1,3].axis('off')\n",
    "\n",
    "            ax[1,4].imshow(E_rec_np)\n",
    "            ax[1,4].set_title('Reconstructed Eosin')\n",
    "            ax[1,4].axis('off')\n",
    "            \n",
    "            if RUNNING_ON_DELFOS:\n",
    "                plt.savefig(f'/home/modej/Deep_Var_BCD/results/dip_images/{epoch}.png', transparent=True)\n",
    "            else:\n",
    "                plt.savefig(f'/home/modejota/Deep_Var_BCD/results/dip_images/{epoch}.png', transparent=True)\n",
    "            plt.close()\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "# Should be executed without generating images to be a valid benchmark of the model/method itself.\n",
    "with open('/home/modej/Deep_Var_BCD/results/dip_images/metricas.txt', 'a') as archivo:\n",
    "    archivo.write(f\"Execution time: {execution_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCDNET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
